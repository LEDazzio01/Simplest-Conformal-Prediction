{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/elainedazzio/simplest-conformal-prediction-example?scriptVersionId=261335989\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# The Absolute Simplest Conformal Prediction Example (For Learning!)\n\nThis notebook shows you the *very basic idea* behind conformal prediction. We're going to keep things incredibly simple to make it easy to understand.\n\n**Important Note:** This example is *only* for learning the core concept. It does *not* follow best practices that you'd need for real-world projects. Specifically, we're going to use all our data for *both* training and calculating how \"wrong\" our model usually is.  This is a shortcut that makes the example easier to grasp, but it will give us prediction intervals that are too narrow (meaning they're more confident than they should be).\n\nLet's get started!","metadata":{}},{"cell_type":"code","source":"# --- 1. Imports ---\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:32.77727Z","iopub.execute_input":"2025-03-15T19:56:32.77751Z","iopub.status.idle":"2025-03-15T19:56:35.018101Z","shell.execute_reply.started":"2025-03-15T19:56:32.777489Z","shell.execute_reply":"2025-03-15T19:56:35.017281Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We've just imported the libraries we need:\n\n*   `numpy`: For numerical operations (like creating arrays).\n*   `matplotlib.pyplot`: For plotting.\n*   `sklearn.linear_model.LinearRegression`: Our simple prediction model.","metadata":{}},{"cell_type":"code","source":"# --- 2. Generate Data ---\n\n# Super simple linear data with noise\nnp.random.seed(42)\nX = np.linspace(0, 10, 100).reshape(-1, 1)  # Reshape for sklearn\ny = 2 * X.flatten() + 1 + np.random.normal(0, 2, 100) # Linear relationship + noise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:35.018792Z","iopub.execute_input":"2025-03-15T19:56:35.019202Z","iopub.status.idle":"2025-03-15T19:56:35.024441Z","shell.execute_reply.started":"2025-03-15T19:56:35.019179Z","shell.execute_reply":"2025-03-15T19:56:35.023428Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we've created some fake data. It's just a simple line with some random \"noise\" added in. This makes it a little more realistic than a perfect line.  We've also made sure that `X` is in the right format for our model (a \"column vector\").","metadata":{}},{"cell_type":"code","source":"# --- 3. Train a Model ---\n\nmodel = LinearRegression()\nmodel.fit(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:35.025377Z","iopub.execute_input":"2025-03-15T19:56:35.025598Z","iopub.status.idle":"2025-03-15T19:56:35.132589Z","shell.execute_reply.started":"2025-03-15T19:56:35.025577Z","shell.execute_reply":"2025-03-15T19:56:35.131647Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We've trained a basic linear regression model. This model tries to find the \"best-fit\" straight line through our data.","metadata":{}},{"cell_type":"code","source":"# --- 4. Make Predictions and Calculate Residuals ---\n\ny_pred = model.predict(X)\nresiduals = np.abs(y - y_pred)  # Absolute residuals as nonconformity scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:35.133472Z","iopub.execute_input":"2025-03-15T19:56:35.133731Z","iopub.status.idle":"2025-03-15T19:56:35.143088Z","shell.execute_reply.started":"2025-03-15T19:56:35.133709Z","shell.execute_reply":"2025-03-15T19:56:35.142324Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here's a key step! We've calculated the \"residuals.\"  A residual is simply how far off each of our model's predictions was from the actual value. We use the *absolute value* of the residuals, so we're only looking at the *size* of the error, not whether it was too high or too low.  These residuals are our **nonconformity scores**. They measure how \"non-conforming\" or \"unusual\" each data point is, *according to our model*.","metadata":{}},{"cell_type":"code","source":"# --- 5.  New Data Point for Prediction ---\nX_new = np.array([[5]]) # Predict at x=5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:35.143856Z","iopub.execute_input":"2025-03-15T19:56:35.144136Z","iopub.status.idle":"2025-03-15T19:56:35.160903Z","shell.execute_reply.started":"2025-03-15T19:56:35.144117Z","shell.execute_reply":"2025-03-15T19:56:35.159724Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We've created a new data point, `X_new`.  This is the `X` value for which we want to make a prediction *and* create a prediction interval.","metadata":{}},{"cell_type":"code","source":"# --- 6. Calculate Prediction Interval ---\n\n# Find the (1-alpha) quantile of the residuals.  Let's use 90% confidence (alpha=0.1)\nalpha = 0.1\nquantile_value = np.quantile(residuals, 1 - alpha)\n\ny_new_pred = model.predict(X_new)\ny_lower = y_new_pred - quantile_value\ny_upper = y_new_pred + quantile_value\n\nprint(f\"Prediction for X={X_new[0,0]}: {y_new_pred[0]:.2f}\")\nprint(f\"90% Prediction Interval: [{y_lower[0]:.2f}, {y_upper[0]:.2f}]\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:35.162965Z","iopub.execute_input":"2025-03-15T19:56:35.163207Z","iopub.status.idle":"2025-03-15T19:56:35.183222Z","shell.execute_reply.started":"2025-03-15T19:56:35.16319Z","shell.execute_reply":"2025-03-15T19:56:35.182082Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This is where the conformal prediction magic happens!\n\n1.  **Choose a Confidence Level:** We've chosen a 90% confidence level (which means `alpha = 0.1`). This means we want our prediction interval to be \"right\" 90% of the time.\n\n2.  **Find the Quantile:** We use `np.quantile` to find the value that separates the bottom 90% of our residuals from the top 10%.  Think of it like this: 90% of our training data points had errors *smaller* than this `quantile_value`.\n\n3.  **Create the Interval:**  We make our prediction for `X_new` using the model.  Then, we create the prediction interval by *adding* and *subtracting* the `quantile_value` from that prediction.  This interval is our \"range of likely values\" for the true `y` value at `X_new`.\n\nWe're essentially saying: \"Based on how wrong our model was on the data it saw, we're 90% confident that the true value for this new `X` will fall within this interval.\"","metadata":{}},{"cell_type":"code","source":"# --- 7. Visualization ---\n\nplt.figure(figsize=(8, 6))\nplt.scatter(X, y, label=\"Training Data\")\nplt.plot(X, y_pred, color='red', label=\"Model Prediction\")\n\n# Show the prediction interval for the new point\nplt.plot([X_new[0,0], X_new[0,0]], [y_lower[0], y_upper[0]], color='green', linestyle='--', linewidth=2, label=\"Prediction Interval\")\nplt.scatter(X_new, y_new_pred, color='green', marker='o', s=100)\n\nplt.xlabel(\"X\")\nplt.ylabel(\"y\")\nplt.title(\"Simplest Conformal Prediction Example\")\nplt.legend()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-15T19:56:35.184444Z","iopub.execute_input":"2025-03-15T19:56:35.184734Z","iopub.status.idle":"2025-03-15T19:56:35.487368Z","shell.execute_reply.started":"2025-03-15T19:56:35.184706Z","shell.execute_reply":"2025-03-15T19:56:35.486286Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Finally, we plot everything:\n\n*   The original data points (blue dots).\n*   The line our model learned (red line).\n*   The new data point we predicted for (green dot).\n*   The prediction interval for that new data point (green dashed line).\n\nYou can see that the interval gives us a range of plausible values, not just a single prediction.\n\n**Important Reminder (Again!)**\n\nRemember, this example is simplified! In a real application, you *must* split your data into training, calibration, and test sets to get valid prediction intervals. This example skips that crucial step to make the core idea of conformal prediction as clear as possible.\n","metadata":{}}]}